{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dbc8ea3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T14:51:48.662970Z",
     "start_time": "2022-01-11T14:51:46.738095Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from utils import Json_Parser\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from dataset import NuSceneDataset\n",
    "from torch import optim,Tensor,unsqueeze\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "from torchvision.models.resnet import resnet50\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import Json_Parser\n",
    "from nuscenes.eval.prediction.splits import get_prediction_challenge_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4304d231",
   "metadata": {},
   "source": [
    "# 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ca4116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T14:52:38.464400Z",
     "start_time": "2022-01-11T14:52:03.261483Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4968/4019853120.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_prediction_challenge_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"E:/Downloads/nuscenes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mvalset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_prediction_challenge_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"val\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"E:/Downloads/nuscenes\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m train_dataloader = DataLoader(NuSceneDataset(train_mode=True, config_file_name=config_file_name, verbose=False), \n\u001b[0m\u001b[0;32m      8\u001b[0m                               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LEARNING'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefetch_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                               pin_memory = True, persistent_workers=False, drop_last = True)\n",
      "\u001b[1;32m~\\Desktop\\nu_prediction\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, train_mode, config_file_name, layers_list, color_list, verbose)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DATASET'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dataset_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# self.intersection_use= config['DATASET']['intersection_use']        # only available for mini_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnuscenes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNuScenes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DATASET'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dataset_str'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhelper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPredictHelper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnuscenes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LEARNING'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_classes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\stgm\\lib\\site-packages\\nuscenes\\nuscenes.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, version, dataroot, verbose, map_resolution)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load_table__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sample'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load_table__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sample_data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_annotation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load_table__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sample_annotation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load_table__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'map'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\stgm\\lib\\site-packages\\nuscenes\\nuscenes.py\u001b[0m in \u001b[0;36m__load_table__\u001b[1;34m(self, table_name)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;34m\"\"\" Loads a table. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtable_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'{}.json'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\stgm\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \"\"\"\n\u001b[1;32m--> 293\u001b[1;33m     return loads(fp.read(),\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config_file_name='./config.json'\n",
    "parser = Json_Parser(config_file_name)\n",
    "config = parser.load_parser()\n",
    "load_mode = config['DATASET'][\"load_mode\"]\n",
    "train_dataloader = DataLoader(NuSceneDataset(train_mode=True, config_file_name=config_file_name, verbose=True), \n",
    "                              batch_size=config['LEARNING']['batch_size'], shuffle=False, num_workers=8, prefetch_factor = 2,\n",
    "                              pin_memory = True, persistent_workers=True, drop_last = False)\n",
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e6e324",
   "metadata": {},
   "source": [
    "# 模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c93dd0c",
   "metadata": {},
   "source": [
    "## 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c976c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T13:08:50.045135Z",
     "start_time": "2022-01-11T13:08:50.029113Z"
    }
   },
   "outputs": [],
   "source": [
    "# 基本参数\n",
    "if config['LEARNING']['device'] == 'cuda:0':\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.enabled = True \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "epochs = 1\n",
    "latent_dim = 256  # LSTM 的单元个数\n",
    "encoder_fc = 64\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "\n",
    "encoder_length = 1 \n",
    "decoder_length = 10\n",
    "num_encoder_tokens = 2\n",
    "num_decoder_tokens = 2\n",
    "z_dimension = 32\n",
    "accumulation_steps = 5 # 梯度累积步数\n",
    "\n",
    "num_classes = config['LEARNING']['num_classes'] # 类数\n",
    "modal_fc = latent_dim*(1+bidirectional) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b625e54e",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c52b4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T13:08:50.061150Z",
     "start_time": "2022-01-11T13:08:50.046137Z"
    }
   },
   "outputs": [],
   "source": [
    "def neg_multi_log_likelihood_batch(\n",
    "    gt: Tensor, pred: Tensor, confidences: Tensor\n",
    ") -> Tensor:\n",
    "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
    "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
    "\n",
    "    assert gt.shape == (batch_size, future_len, num_coords), f\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\n",
    "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
    "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
    "#     assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
    "    # assert all data are valid\n",
    "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
    "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
    "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
    "#     assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
    "\n",
    "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
    "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
    "#     avails = avails[:, None, :, None]  # add modes and cords\n",
    "\n",
    "    # error (batch_size, num_modes, future_len)\n",
    "    error = torch.sum(((gt - pred)) ** 2, dim=-1)  # reduce coords and use availability\n",
    "\n",
    "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
    "        # error (batch_size, num_modes)\n",
    "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
    "\n",
    "    # use max aggregator on modes for numerical stability\n",
    "    # error (batch_size, num_modes)\n",
    "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
    "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
    "    # print(\"error\", error)\n",
    "    return torch.mean(error)\n",
    "\n",
    "def loss_function(y_hat, confidences, data, mean1, std1, mean2, std2):\n",
    "    label = data['label'].to(device)\n",
    "    y_true = data[\"target_positions\"].to(device)\n",
    "#     MSE = F.mse_loss(y_hat, y_true, reduction='none')\n",
    "#     MSE = MSE * y_availabilities\n",
    "#     MSE = MSE.mean()\n",
    "    Cross = F.binary_cross_entropy_with_logits(confidences, label)\n",
    "    NLL = neg_multi_log_likelihood_batch(\n",
    "        y_true, y_hat, confidences)\n",
    "    # 因为var是标准差的自然对数，先求自然对数然后平方转换成方差\n",
    "    var1 = torch.pow(torch.exp(std1), 2)\n",
    "    var2 = torch.pow(torch.exp(std2), 2)\n",
    "    KLD1 = -0.5 * torch.mean(1+torch.log(var1)-torch.pow(mean1, 2)-var1)\n",
    "    KLD1 = torch.max(KLD1,torch.ones_like(KLD1))\n",
    "    KLD2 = -0.5 * torch.mean(1+torch.log(var2)-torch.pow(mean2, 2)-var2)\n",
    "    KLD2 = torch.max(KLD2,torch.ones_like(KLD2))\n",
    "    KLD = KLD1 + KLD2\n",
    "#     print('KLD: ',KLD,' NLL: ',NLL,' Cross: ', Cross)\n",
    "    return NLL, KLD, Cross"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f40dc",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadac25e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T13:08:52.489804Z",
     "start_time": "2022-01-11T13:08:50.062152Z"
    }
   },
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CVAE, self).__init__()\n",
    "\n",
    "        # 定义序列编码器\n",
    "        self.encoder = nn.LSTM(\n",
    "            num_encoder_tokens, latent_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        self.encoder2 = nn.Linear(latent_dim*(1+bidirectional), encoder_fc)\n",
    "#         self.encoder2 = nn.Linear(latent_dim*(1+bidirectional)+modal_fc, encoder_fc)\n",
    "#         self.encoder_mean1 = nn.Linear(latent_dim*(1+bidirectional), 64)\n",
    "        self.encoder_mean2 = nn.Linear(encoder_fc, z_dimension)\n",
    "#         self.encoder_std1 = nn.Linear(latent_dim*(1+bidirectional), 32)\n",
    "        self.encoder_std2 = nn.Linear(encoder_fc, z_dimension)\n",
    "\n",
    "        # 定义序列解码器\n",
    "        self.decoder = nn.LSTM(z_dimension*2, latent_dim, num_layers=num_layers,\n",
    "                               bidirectional=bidirectional, batch_first=True)\n",
    "        self.decoder_fc = nn.Linear(latent_dim*(1+bidirectional), 64)\n",
    "        self.decoder_fc1 = nn.Linear(64, num_decoder_tokens*num_classes)\n",
    "#         self.decoder_fc2 = nn.Linear(64, num_decoder_tokens)\n",
    "#         self.decoder_fc3 = nn.Linear(64, num_decoder_tokens)\n",
    "        self.decoder_confi = nn.Linear(num_decoder_tokens*num_classes, num_classes)\n",
    "\n",
    "        # 定义图像编码器\n",
    "        # load pre-trained Conv2D model\n",
    "        self.resnet = resnet50(pretrained=True)\n",
    "        # change input channels number to match the rasterizer's output\n",
    "        num_in_channels = 3\n",
    "        self.resnet.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.resnet.conv1.out_channels,\n",
    "            kernel_size=self.resnet.conv1.kernel_size,\n",
    "            stride=self.resnet.conv1.stride,\n",
    "            padding=self.resnet.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        # change output size to (X, Y) * number of future states\n",
    "        num_targets = z_dimension * decoder_length\n",
    "        self.resnet.fc = nn.Linear(in_features=2048, out_features=512)\n",
    "        self.encoder_mean3 = nn.Linear(512, num_targets)\n",
    "        self.encoder_std3 = nn.Linear(512, num_targets)\n",
    "        \n",
    "        #定义采样器\n",
    "        self.sampler_fc1 = nn.Linear(3,1024)\n",
    "        self.sampler_fc2 = nn.Linear(1024,512)\n",
    "        self.sampler_fc3 = nn.Linear(512,z_dimension * decoder_length)\n",
    "        \n",
    "        #定义行为预测\n",
    "        self.modal1 = nn.LSTM(\n",
    "            num_encoder_tokens, latent_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        self.modal2 = nn.Linear(latent_dim*(1+bidirectional), num_classes)\n",
    "        \n",
    "    def noise_reparameterize(self, mean, logvar):\n",
    "        eps = torch.randn(mean.shape).to(device)\n",
    "        z = mean + eps * torch.exp(logvar)\n",
    "        return z\n",
    "\n",
    "    def forward(self, data):\n",
    "#         print(data[\"history_positions\"])\n",
    "        inputs1 = data[\"history_positions\"].to(device)\n",
    "        inputs1 = inputs1.cuda(non_blocking=True).float()\n",
    "#         yaw = torch.FloatTensor(data[\"history_yaws\"]).to(device)\n",
    "        if inputs1.dim() == 2:\n",
    "            inputs1 = torch.unsqueeze(inputs1, 0)\n",
    "\n",
    "        h0 = torch.autograd.Variable(torch.randn(\n",
    "            num_layers*(1+bidirectional), inputs1.size()[0], latent_dim)).to(device)\n",
    "        c0 = torch.autograd.Variable(torch.randn(\n",
    "            num_layers*(1+bidirectional), inputs1.size()[0], latent_dim)).to(device)\n",
    "\n",
    "        inputs21 = data[\"image\"].to(device)\n",
    "#         inputs21 = inputs21.float()\n",
    "        inputs2 = inputs21.cuda(non_blocking=True).permute(0, 3, 1, 2).float()\n",
    "        if inputs2.dim() == 3:\n",
    "            inputs2 = torch.unsqueeze(inputs2, 0)\n",
    "\n",
    "        out1, _ = self.encoder(inputs1, (h0, c0))\n",
    "#         out1 = out1[:,-1,:]\n",
    "#         out1 = torch.unsqueeze(out1, 1)\n",
    "#         out1 = out1.expand(out1.size()[0],decoder_length,out1.size()[-1])\n",
    "        out1 = F.relu(self.encoder2(out1), inplace=True)\n",
    "        \n",
    "        out_modal, _ = self.modal1(inputs1, (h0, c0))\n",
    "        out_modal = F.softmax(self.modal2(out_modal[:, -1, :]), dim = -1)\n",
    "\n",
    "#         mean1 = F.relu(self.encoder_mean1(out1), inplace=True)\n",
    "        mean2 = F.relu(self.encoder_mean2(out1), inplace=True)\n",
    "#         logstd1 = F.relu(self.encoder_std1(out1), inplace=True)\n",
    "        logstd2 = F.relu(self.encoder_std2(out1), inplace=True)\n",
    "        # prevent from poster vanish\n",
    "#         logstd2 = torch.abs(logstd2) + 0.6\n",
    "\n",
    "        z1 = self.noise_reparameterize(mean2, logstd2)\n",
    "        z1 = z1[:, -1, :]\n",
    "        z1 = torch.unsqueeze(z1, 1)\n",
    "        z1 = z1.expand(z1.size()[0], decoder_length, z1.size()[-1])\n",
    "\n",
    "        out12 = self.resnet(inputs2)\n",
    "        mean3 = F.relu(self.encoder_mean3(out12), inplace=True)\n",
    "        logstd3 = F.relu(self.encoder_std3(out12), inplace=True)\n",
    "        z2 = self.noise_reparameterize(mean3, logstd3)\n",
    "        z2 = z2.reshape(z1.size())\n",
    "        z = torch.cat([z1, z2], -1)\n",
    "        out2, _ = self.decoder(z)\n",
    "        out2 = F.relu(self.decoder_fc(out2), inplace=True)\n",
    "\n",
    "        out21 = F.relu(self.decoder_fc1(out2), inplace=True)\n",
    "#         out22 = F.relu(self.decoder_fc2(out2), inplace=True)\n",
    "#         out23 = F.relu(self.decoder_fc3(out2), inplace=True)\n",
    "        confidences = F.softmax(self.decoder_confi(out21)[:, -1, :], dim=-1)\n",
    "        confidences = F.softmax(confidences * out_modal, dim=-1)\n",
    "        \n",
    "        out3 = torch.split(out21,2,dim=-1)\n",
    "        y_hat = torch.Tensor([]).to(device)\n",
    "        for i in out3:\n",
    "            i = torch.unsqueeze(i, 1) \n",
    "            y_hat=torch.cat([y_hat,i],dim=1)\n",
    "\n",
    "        return y_hat, confidences, mean2, logstd2, mean3, logstd3\n",
    "\n",
    "# 创建对象\n",
    "cvae = CVAE().to(device)\n",
    "# vae.load_state_dict(torch.load('./VAE_z2.pth'))\n",
    "cvae_optimizer = torch.optim.Adam(cvae.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea942ff",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b9635",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T13:08:52.696281Z",
     "start_time": "2022-01-11T13:08:52.490806Z"
    }
   },
   "outputs": [],
   "source": [
    "if not load_mode:    \n",
    "    # ==== TRAIN LOOP\n",
    "    losses_avg = []\n",
    "    for epoch in range(epochs):  # 进行多个epoch的训练\n",
    "        tr_it = iter(train_dataloader)\n",
    "        progress_bar = tqdm(range(len(train_dataloader)//1),position=0)\n",
    "        losses_train = []\n",
    "        cvae_optimizer.zero_grad(set_to_none = True)\n",
    "        for i in progress_bar:\n",
    "            try:\n",
    "                data = next(tr_it)\n",
    "            except StopIteration:\n",
    "                tr_it = iter(train_dataloader)\n",
    "                data = next(tr_it)\n",
    "            cvae.train() # 设置为训练模式\n",
    "            torch.set_grad_enabled(True)\n",
    "#             print(data[\"image\"].size(),data[\"history_positions\"].size(),data[\"target_positions\"].size())\n",
    "            y_hat, confidences, mean1, std1, mean2, std2 = cvae(data)  # 输入\n",
    "            if device == torch.device('cuda:0'):\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    NLL,KLD,Cross = loss_function(y_hat, confidences, data, mean1, std1, mean2, std2)\n",
    "                    loss = NLL + (25)*KLD + 20*Cross\n",
    "#                     if i + 1>= len(train_dataloader)//1:\n",
    "#                         print(NLL,KLD,Cross)\n",
    "            else:\n",
    "                NLL,KLD,Cross = loss_function(y_hat, confidences, data, mean1, std1, mean2, std2)\n",
    "                loss = NLL + (25)*KLD + 20*Cross\n",
    "#                 if i + 1>= len(train_dataloader)//1:\n",
    "#                     print(NLL,KLD,Cross)\n",
    "\n",
    "            # Backward pass\n",
    "            # 梯度累积模式\n",
    "#             loss = loss / accumulation_steps\n",
    "#             loss.backward() \n",
    "#             if (i+1) % accumulation_steps == 0:\n",
    "#                 cvae_optimizer.step()\n",
    "#                 cvae_optimizer.zero_grad(set_to_none = True)\n",
    "\n",
    "            # 无梯度累积模式\n",
    "            cvae_optimizer.zero_grad(set_to_none = True)\n",
    "            loss.backward()\n",
    "            cvae_optimizer.step()\n",
    "            losses_train.append(loss.item())\n",
    "            progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)}\")\n",
    "        losses_avg.append(np.mean(losses_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea78ca26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T13:08:52.697281Z",
     "start_time": "2022-01-11T13:08:52.697281Z"
    }
   },
   "outputs": [],
   "source": [
    "if not load_mode:    \n",
    "    torch.save(cvae.state_dict(),'E:/Downloads/nuscenes/cvae.pth')\n",
    "    plt.plot(np.arange(len(losses_train)), losses_train, label=\"train loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a8ddf",
   "metadata": {},
   "source": [
    "# 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0335e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T13:08:52.698282Z",
     "start_time": "2022-01-11T13:08:52.698282Z"
    }
   },
   "outputs": [],
   "source": [
    "# from nuscenes.eval.prediction.metrics import MinADEK, MinFDEK, MissRateTopK, OffRoadRate\n",
    "\n",
    "config_file_name='./config.json'\n",
    "parser = Json_Parser(config_file_name)\n",
    "config = parser.load_parser()\n",
    "eval_dataloader = DataLoader(NuSceneDataset(train_mode=False, config_file_name=config_file_name, verbose=False), \n",
    "                              batch_size=1, shuffle=True, num_workers=8, prefetch_factor = 2,\n",
    "                              pin_memory = True, persistent_workers=True)\n",
    "len(eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c35eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T13:08:52.699283Z",
     "start_time": "2022-01-11T13:08:52.699283Z"
    }
   },
   "outputs": [],
   "source": [
    "from nuscenes.eval.prediction.data_classes import Prediction\n",
    "\n",
    "# ==== EVAL LOOP\n",
    "cvae.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "tr_it = iter(eval_dataloader)\n",
    "progress_bar = tqdm(range(len(eval_dataloader)//1),position=0)\n",
    "cvae.load_state_dict(torch.load('E:/Downloads/nuscenes/cvae.pth'))\n",
    "cvae_preds = []\n",
    "\n",
    "for i in progress_bar:\n",
    "    try:\n",
    "        data = next(tr_it)\n",
    "    except StopIteration:\n",
    "        tr_it = iter(eval_dataloader)\n",
    "        data = next(tr_it)\n",
    "    y_hat, confidences,mean1,std1,mean2,std2 = cvae(data)\n",
    "    y = y_hat.squeeze(dim=0).detach().cpu().numpy()\n",
    "    conf = confidences.detach().cpu().numpy()\n",
    "#     print(conf)\n",
    "    cvae_preds.append(Prediction(data['instance'][0], data['sample'][0], y, conf[0]).serialize())\n",
    "json.dump(cvae_preds, open(os.path.join('E:/Downloads/nuscenes', \"cvae_preds.json\"), \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9845117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T13:08:52.700283Z",
     "start_time": "2022-01-11T13:08:52.700283Z"
    }
   },
   "outputs": [],
   "source": [
    "from nuscenes.eval.prediction.compute_metrics import main\n",
    "# if config['DATASET']['set'] == 'train':\n",
    "#     version = 'train'\n",
    "# elif config['DATASET']['set'] == 'mini' and load_mode==True:            \n",
    "#     version = \"mini_val\"\n",
    "# else:\n",
    "#     version = \"mini_train\"\n",
    "\n",
    "main(version=config['DATASET']['dataset_str'],data_root=config['DATASET']['dataset_path'], submission_path='E:/Downloads/nuscenes/cvae_preds.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d847bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stgm",
   "language": "python",
   "name": "stgm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
