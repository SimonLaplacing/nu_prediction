{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dbc8ea3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:57:10.520943Z",
     "start_time": "2022-01-11T16:57:08.917914Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datetime import datetime\n",
    "from utils import Json_Parser\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from dataset import NuSceneDataset\n",
    "from torch import optim,Tensor,unsqueeze\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "from torchvision.models.resnet import resnet50\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import Json_Parser\n",
    "from nuscenes.eval.prediction.splits import get_prediction_challenge_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4304d231",
   "metadata": {},
   "source": [
    "# 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ca4116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:58:06.156156Z",
     "start_time": "2022-01-11T16:57:11.684952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 45.650 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 7.6 seconds.\n",
      "======\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16093"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file_name='./config.json'\n",
    "parser = Json_Parser(config_file_name)\n",
    "config = parser.load_parser()\n",
    "load_mode = config['DATASET'][\"load_mode\"]\n",
    "train_dataloader = DataLoader(NuSceneDataset(train_mode=True, config_file_name=config_file_name, verbose=True), \n",
    "                              batch_size=config['LEARNING']['batch_size'], shuffle=False, num_workers=6, prefetch_factor = 2,\n",
    "                              pin_memory = True, persistent_workers=True, drop_last = False)\n",
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e6e324",
   "metadata": {},
   "source": [
    "# 模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c93dd0c",
   "metadata": {},
   "source": [
    "## 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5c976c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T15:00:27.270351Z",
     "start_time": "2022-01-11T15:00:27.255337Z"
    }
   },
   "outputs": [],
   "source": [
    "# 基本参数\n",
    "if config['LEARNING']['device'] == 'cuda:0':\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.enabled = True \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "epochs = 1\n",
    "latent_dim = 256  # LSTM 的单元个数\n",
    "encoder_fc = 64\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "\n",
    "encoder_length = 1 \n",
    "decoder_length = 10\n",
    "num_encoder_tokens = 2\n",
    "num_decoder_tokens = 2\n",
    "z_dimension = 32\n",
    "accumulation_steps = 5 # 梯度累积步数\n",
    "\n",
    "num_classes = config['LEARNING']['num_classes'] # 类数\n",
    "modal_fc = latent_dim*(1+bidirectional) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b625e54e",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67c52b4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T15:00:27.286357Z",
     "start_time": "2022-01-11T15:00:27.271352Z"
    }
   },
   "outputs": [],
   "source": [
    "def neg_multi_log_likelihood_batch(\n",
    "    gt: Tensor, pred: Tensor, confidences: Tensor\n",
    ") -> Tensor:\n",
    "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
    "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
    "\n",
    "    assert gt.shape == (batch_size, future_len, num_coords), f\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\n",
    "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
    "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
    "#     assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
    "    # assert all data are valid\n",
    "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
    "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
    "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
    "#     assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
    "\n",
    "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
    "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
    "#     avails = avails[:, None, :, None]  # add modes and cords\n",
    "\n",
    "    # error (batch_size, num_modes, future_len)\n",
    "    error = torch.sum(((gt - pred)) ** 2, dim=-1)  # reduce coords and use availability\n",
    "    del gt\n",
    "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
    "        # error (batch_size, num_modes)\n",
    "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
    "\n",
    "    # use max aggregator on modes for numerical stability\n",
    "    # error (batch_size, num_modes)\n",
    "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
    "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
    "    del max_value\n",
    "    return torch.mean(error)\n",
    "\n",
    "def loss_function(y_hat, confidences, data, mean1, std1, mean2, std2):\n",
    "    label = data['label'].to(device)\n",
    "    y_true = data[\"target_positions\"].to(device)\n",
    "#     MSE = F.mse_loss(y_hat, y_true, reduction='none')\n",
    "#     MSE = MSE * y_availabilities\n",
    "#     MSE = MSE.mean()\n",
    "    Cross = F.binary_cross_entropy_with_logits(confidences, label)\n",
    "    del label\n",
    "    NLL = neg_multi_log_likelihood_batch(\n",
    "        y_true, y_hat, confidences)\n",
    "    # 因为var是标准差的自然对数，先求自然对数然后平方转换成方差\n",
    "    var1 = torch.pow(torch.exp(std1), 2)\n",
    "    var2 = torch.pow(torch.exp(std2), 2)\n",
    "    KLD1 = -0.5 * torch.mean(1+torch.log(var1)-torch.pow(mean1, 2)-var1)\n",
    "    KLD1 = torch.max(KLD1,torch.ones_like(KLD1))\n",
    "    KLD2 = -0.5 * torch.mean(1+torch.log(var2)-torch.pow(mean2, 2)-var2)\n",
    "    KLD2 = torch.max(KLD2,torch.ones_like(KLD2))\n",
    "    KLD = KLD1 + KLD2\n",
    "    del KLD1, KLD2, var1, var2, y_true\n",
    "#     print('KLD: ',KLD,' NLL: ',NLL,' Cross: ', Cross)\n",
    "    return NLL, KLD, Cross"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f40dc",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fadac25e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T15:00:30.756522Z",
     "start_time": "2022-01-11T15:00:27.287358Z"
    }
   },
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CVAE, self).__init__()\n",
    "\n",
    "        # 定义序列编码器\n",
    "        self.encoder = nn.LSTM(\n",
    "            num_encoder_tokens, latent_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        self.encoder2 = nn.Linear(latent_dim*(1+bidirectional), encoder_fc)\n",
    "#         self.encoder2 = nn.Linear(latent_dim*(1+bidirectional)+modal_fc, encoder_fc)\n",
    "#         self.encoder_mean1 = nn.Linear(latent_dim*(1+bidirectional), 64)\n",
    "        self.encoder_mean2 = nn.Linear(encoder_fc, z_dimension)\n",
    "#         self.encoder_std1 = nn.Linear(latent_dim*(1+bidirectional), 32)\n",
    "        self.encoder_std2 = nn.Linear(encoder_fc, z_dimension)\n",
    "\n",
    "        # 定义序列解码器\n",
    "        self.decoder = nn.LSTM(z_dimension*2, latent_dim, num_layers=num_layers,\n",
    "                               bidirectional=bidirectional, batch_first=True)\n",
    "        self.decoder_fc = nn.Linear(latent_dim*(1+bidirectional), 64)\n",
    "        self.decoder_fc1 = nn.Linear(64, num_decoder_tokens*num_classes)\n",
    "#         self.decoder_fc2 = nn.Linear(64, num_decoder_tokens)\n",
    "#         self.decoder_fc3 = nn.Linear(64, num_decoder_tokens)\n",
    "        self.decoder_confi = nn.Linear(num_decoder_tokens*num_classes, num_classes)\n",
    "\n",
    "        # 定义图像编码器\n",
    "        # load pre-trained Conv2D model\n",
    "        self.resnet = resnet50(pretrained=True)\n",
    "        # change input channels number to match the rasterizer's output\n",
    "        num_in_channels = 3\n",
    "        self.resnet.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.resnet.conv1.out_channels,\n",
    "            kernel_size=self.resnet.conv1.kernel_size,\n",
    "            stride=self.resnet.conv1.stride,\n",
    "            padding=self.resnet.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        # change output size to (X, Y) * number of future states\n",
    "        num_targets = z_dimension * decoder_length\n",
    "        self.resnet.fc = nn.Linear(in_features=2048, out_features=512)\n",
    "        self.encoder_mean3 = nn.Linear(512, num_targets)\n",
    "        self.encoder_std3 = nn.Linear(512, num_targets)\n",
    "        \n",
    "        #定义采样器\n",
    "        self.sampler_fc1 = nn.Linear(3,1024)\n",
    "        self.sampler_fc2 = nn.Linear(1024,512)\n",
    "        self.sampler_fc3 = nn.Linear(512,z_dimension * decoder_length)\n",
    "        \n",
    "        #定义行为预测\n",
    "        self.modal1 = nn.LSTM(\n",
    "            num_encoder_tokens, latent_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
    "        self.modal2 = nn.Linear(latent_dim*(1+bidirectional), num_classes)\n",
    "        \n",
    "    def noise_reparameterize(self, mean, logvar):\n",
    "        eps = torch.randn(mean.shape).to(device)\n",
    "        z = mean + eps * torch.exp(logvar)\n",
    "        del eps\n",
    "        return z\n",
    "\n",
    "    def forward(self, data):\n",
    "#         print(data[\"history_positions\"])\n",
    "        inputs1 = data[\"history_positions\"].to(device)\n",
    "        inputs1 = inputs1.cuda(non_blocking=True).float()\n",
    "#         yaw = torch.FloatTensor(data[\"history_yaws\"]).to(device)\n",
    "        if inputs1.dim() == 2:\n",
    "            inputs1 = torch.unsqueeze(inputs1, 0)\n",
    "\n",
    "        h0 = torch.autograd.Variable(torch.randn(\n",
    "            num_layers*(1+bidirectional), inputs1.size()[0], latent_dim)).to(device)\n",
    "        c0 = torch.autograd.Variable(torch.randn(\n",
    "            num_layers*(1+bidirectional), inputs1.size()[0], latent_dim)).to(device)\n",
    "\n",
    "        inputs21 = data[\"image\"].to(device)\n",
    "#         inputs21 = inputs21.float()\n",
    "        inputs2 = inputs21.cuda(non_blocking=True).permute(0, 3, 1, 2).float()\n",
    "        if inputs2.dim() == 3:\n",
    "            inputs2 = torch.unsqueeze(inputs2, 0)\n",
    "\n",
    "        out1, _ = self.encoder(inputs1, (h0, c0))\n",
    "#         out1 = out1[:,-1,:]\n",
    "#         out1 = torch.unsqueeze(out1, 1)\n",
    "#         out1 = out1.expand(out1.size()[0],decoder_length,out1.size()[-1])\n",
    "        out1 = F.relu(self.encoder2(out1), inplace=True)\n",
    "        \n",
    "        out_modal, _ = self.modal1(inputs1, (h0, c0))\n",
    "        out_modal = F.softmax(self.modal2(out_modal[:, -1, :]), dim = -1)\n",
    "\n",
    "#         mean1 = F.relu(self.encoder_mean1(out1), inplace=True)\n",
    "        mean2 = F.relu(self.encoder_mean2(out1), inplace=True)\n",
    "#         logstd1 = F.relu(self.encoder_std1(out1), inplace=True)\n",
    "        logstd2 = F.relu(self.encoder_std2(out1), inplace=True)\n",
    "        # prevent from poster vanish\n",
    "#         logstd2 = torch.abs(logstd2) + 0.6\n",
    "\n",
    "        z1 = self.noise_reparameterize(mean2, logstd2)\n",
    "        z1 = z1[:, -1, :]\n",
    "        z1 = torch.unsqueeze(z1, 1)\n",
    "        z1 = z1.expand(z1.size()[0], decoder_length, z1.size()[-1])\n",
    "\n",
    "        out12 = self.resnet(inputs2)\n",
    "        mean3 = F.relu(self.encoder_mean3(out12), inplace=True)\n",
    "        logstd3 = F.relu(self.encoder_std3(out12), inplace=True)\n",
    "        z2 = self.noise_reparameterize(mean3, logstd3)\n",
    "        z2 = z2.reshape(z1.size())\n",
    "        z = torch.cat([z1, z2], -1)\n",
    "        out2, _ = self.decoder(z)\n",
    "        out2 = F.relu(self.decoder_fc(out2), inplace=True)\n",
    "\n",
    "        out21 = F.relu(self.decoder_fc1(out2), inplace=True)\n",
    "#         out22 = F.relu(self.decoder_fc2(out2), inplace=True)\n",
    "#         out23 = F.relu(self.decoder_fc3(out2), inplace=True)\n",
    "        confidences = F.softmax(self.decoder_confi(out21)[:, -1, :], dim=-1)\n",
    "        confidences = F.softmax(confidences * out_modal, dim=-1)\n",
    "        \n",
    "        out3 = torch.split(out21,2,dim=-1)\n",
    "        y_hat = torch.Tensor([]).to(device)\n",
    "        for i in out3:\n",
    "            i = torch.unsqueeze(i, 1) \n",
    "            y_hat=torch.cat([y_hat,i],dim=1)\n",
    "\n",
    "        return y_hat, confidences, mean2, logstd2, mean3, logstd3\n",
    "\n",
    "# 创建对象\n",
    "cvae = CVAE().to(device)\n",
    "# vae.load_state_dict(torch.load('./VAE_z2.pth'))\n",
    "cvae_optimizer = torch.optim.Adam(cvae.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea942ff",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "421b9635",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T15:02:27.995902Z",
     "start_time": "2022-01-11T15:00:30.757522Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13800/3005627164.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlosses_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 进行多个epoch的训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtr_it\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mprogress_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mlosses_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\stgm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_workers\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\stgm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\stgm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\stgm\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\stgm\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\stgm\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\stgm\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\stgm\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "if not load_mode:    \n",
    "    # ==== TRAIN LOOP\n",
    "    losses_avg = []\n",
    "    for epoch in range(epochs):  # 进行多个epoch的训练\n",
    "        tr_it = iter(train_dataloader)\n",
    "        progress_bar = tqdm(range(len(train_dataloader)//1),position=0)\n",
    "        losses_train = []\n",
    "        cvae_optimizer.zero_grad(set_to_none = True)\n",
    "        for i in progress_bar:\n",
    "            try:\n",
    "                data = next(tr_it)\n",
    "            except StopIteration:\n",
    "                tr_it = iter(train_dataloader)\n",
    "                data = next(tr_it)\n",
    "            cvae.train() # 设置为训练模式\n",
    "            torch.set_grad_enabled(True)\n",
    "#             print(data[\"image\"].size(),data[\"history_positions\"].size(),data[\"target_positions\"].size())\n",
    "            y_hat, confidences, mean1, std1, mean2, std2 = cvae(data)  # 输入\n",
    "            if device == torch.device('cuda:0'):\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    NLL,KLD,Cross = loss_function(y_hat, confidences, data, mean1, std1, mean2, std2)\n",
    "                    loss = NLL + (25)*KLD + 20*Cross\n",
    "#                     if i + 1>= len(train_dataloader)//1:\n",
    "#                         print(NLL,KLD,Cross)\n",
    "            else:\n",
    "                NLL,KLD,Cross = loss_function(y_hat, confidences, data, mean1, std1, mean2, std2)\n",
    "                loss = NLL + (25)*KLD + 20*Cross\n",
    "#                 if i + 1>= len(train_dataloader)//1:\n",
    "#                     print(NLL,KLD,Cross)\n",
    "            del NLL, KLD, Cross, y_hat, confidences, mean1, std1, mean2, std2, data\n",
    "            # Backward pass\n",
    "            # 梯度累积模式\n",
    "#             loss = loss / accumulation_steps\n",
    "#             loss.backward() \n",
    "#             if (i+1) % accumulation_steps == 0:\n",
    "#                 cvae_optimizer.step()\n",
    "#                 cvae_optimizer.zero_grad(set_to_none = True)\n",
    "\n",
    "            # 无梯度累积模式\n",
    "            cvae_optimizer.zero_grad(set_to_none = True)\n",
    "            loss.backward()\n",
    "            cvae_optimizer.step()\n",
    "            losses_train.append(loss.item())\n",
    "            progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)}\")\n",
    "            del loss\n",
    "        losses_avg.append(np.mean(losses_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea78ca26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T15:02:28.000908Z",
     "start_time": "2022-01-11T15:02:28.000908Z"
    }
   },
   "outputs": [],
   "source": [
    "if not load_mode:    \n",
    "    torch.save(cvae.state_dict(),config['DATASET'][\"dataset_path']+'/cvae.pth')\n",
    "    plt.plot(np.arange(len(losses_train)), losses_train, label=\"train loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a8ddf",
   "metadata": {},
   "source": [
    "# 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0335e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T15:02:28.003910Z",
     "start_time": "2022-01-11T15:02:28.003910Z"
    }
   },
   "outputs": [],
   "source": [
    "# from nuscenes.eval.prediction.metrics import MinADEK, MinFDEK, MissRateTopK, OffRoadRate\n",
    "\n",
    "config_file_name='./config.json'\n",
    "parser = Json_Parser(config_file_name)\n",
    "config = parser.load_parser()\n",
    "eval_dataloader = DataLoader(NuSceneDataset(train_mode=False, config_file_name=config_file_name, verbose=False), \n",
    "                              batch_size=1, shuffle=True, num_workers=8, prefetch_factor = 2,\n",
    "                              pin_memory = True, persistent_workers=True)\n",
    "len(eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c35eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T15:02:28.006912Z",
     "start_time": "2022-01-11T15:02:28.006912Z"
    }
   },
   "outputs": [],
   "source": [
    "from nuscenes.eval.prediction.data_classes import Prediction\n",
    "\n",
    "# ==== EVAL LOOP\n",
    "cvae.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "tr_it = iter(eval_dataloader)\n",
    "progress_bar = tqdm(range(len(eval_dataloader)//1),position=0)\n",
    "cvae.load_state_dict(torch.load(config['DATASET'][\"dataset_path']+'/cvae.pth'))\n",
    "cvae_preds = []\n",
    "\n",
    "for i in progress_bar:\n",
    "    try:\n",
    "        data = next(tr_it)\n",
    "    except StopIteration:\n",
    "        tr_it = iter(eval_dataloader)\n",
    "        data = next(tr_it)\n",
    "    y_hat, confidences,mean1,std1,mean2,std2 = cvae(data)\n",
    "    y = y_hat.squeeze(dim=0).detach().cpu().numpy()\n",
    "    conf = confidences.detach().cpu().numpy()\n",
    "#     print(conf)\n",
    "    cvae_preds.append(Prediction(data['instance'][0], data['sample'][0], y, conf[0]).serialize())\n",
    "json.dump(cvae_preds, open(os.path.join(config['DATASET'][\"dataset_path'], \"cvae_preds.json\"), \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9845117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T15:02:28.006912Z",
     "start_time": "2022-01-11T15:02:28.006912Z"
    }
   },
   "outputs": [],
   "source": [
    "from nuscenes.eval.prediction.compute_metrics import main\n",
    "# if config['DATASET']['set'] == 'train':\n",
    "#     version = 'train'\n",
    "# elif config['DATASET']['set'] == 'mini' and load_mode==True:            \n",
    "#     version = \"mini_val\"\n",
    "# else:\n",
    "#     version = \"mini_train\"\n",
    "\n",
    "main(version=config['DATASET']['dataset_str'],data_root=config['DATASET']['dataset_path'], submission_path=config['DATASET'][\"dataset_path']+'/cvae_preds.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d847bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stgm",
   "language": "python",
   "name": "stgm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
